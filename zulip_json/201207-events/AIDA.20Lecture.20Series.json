[
    {
        "content": "<p>On behalf of the <a href=\"https://www.vision4ai.eu/\">VISION Project</a>, I would like to invite you to a unique series of AI lectures, that are being regularly prepared in cooperation with the main European AI initiatives and four newly emerging European networks of AI excellence centres (ICT48).</p>\n<p><strong>Lecture by Prof. Pietro Perona: Measuring algorithmic bias in face analysis — towards an experimental approach</strong></p>\n<p><span aria-label=\"calendar\" class=\"emoji emoji-1f4c5\" role=\"img\" title=\"calendar\">:calendar:</span> Tuesday <strong>Feb 23rd, 2021 17:00 – 18:00 CET</strong><br>\n<span aria-label=\"point right\" class=\"emoji emoji-1f449\" role=\"img\" title=\"point right\">:point_right:</span> Please use the following zoom link to attend the lecture: <a href=\"https://authgr.zoom.us/j/98481711168\">https://authgr.zoom.us/j/98481711168</a><br>\n<span aria-label=\"light bulb\" class=\"emoji emoji-1f4a1\" role=\"img\" title=\"light bulb\">:light_bulb:</span> Learn more about the lecture: <a href=\"http://www.i-aida.org/future-lectures/\">http://www.i-aida.org/future-lectures/</a></p>\n<p>The lecture is FREE!</p>\n<p>Abstract: Measuring algorithmic bias is crucial both to assess algorithmic fairness, and to guide the improvement of algorithms. Current methods to measure algorithmic bias in computer vision, which are based on observational datasets, are inadequate for this task because they conflate algorithmic bias with dataset bias. To address this problem I will propose experimental method for measuring algorithmic bias of face analysis algorithms, which manipulates directly the attributes of interest, e.g., gender and skin tone, in order to reveal causal links between attribute variation and performance change. The method is based on generating synthetic “transects” of matched sample images that are designed to differ along specific attributes while leaving other attributes constant. A crucial aspect of our approach is relying on the perception of human observers, both to guide manipulations, and to measure algorithmic bias. Besides allowing the measurement of algorithmic bias, synthetic transects have other advantages with respect to observational datasets: sampling  attributes more evenly, allowing for more straightforward bias analysis on minority and intersectional groups, enabling prediction of bias in new scenarios, reducing ethical and legal challenges, and they are economical and fast to obtain, helping make bias testing affordable and widely available. The method is validated by comparing it to a study that employs the traditional observational method for analyzing bias in gender classification algorithms. The two methods reach different conclusions. While the observational method reports gender and skin color biases, the experimental method reveals biases due to gender, hair length, age, and facial hair.</p>",
        "id": 225805545,
        "sender_full_name": "Anna Tahovská (CLAIRE Office, CZ)",
        "timestamp": 1612945360
    }
]