---
layout: archive
title: Zulip Chat Archive
permalink: /stream/201207-events/topic/AIDA.20Lecture.20Series.html
---

<h2>Stream: <a href="https://claire4ai.github.io/archive/stream/201207-events/index.html">events</a></h2>
<h3>Topic: <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/AIDA.20Lecture.20Series.html">AIDA Lecture Series</a></h3>

<hr>

<base href="https://claire.zulipchat.com">

<head><link href="https://claire4ai.github.io/archive/style.css" rel="stylesheet"></head>

{% raw %}

<a name="225805545"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/AIDA%20Lecture%20Series/near/225805545" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anna Tahovská (CLAIRE Office, CZ) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/AIDA.20Lecture.20Series.html#225805545">(Feb 10 2021 at 08:22)</a>:</h4>
<p>On behalf of the <a href="https://www.vision4ai.eu/">VISION Project</a>, I would like to invite you to a unique series of AI lectures, that are being regularly prepared in cooperation with the main European AI initiatives and four newly emerging European networks of AI excellence centres (ICT48).</p>
<p><strong>Lecture by Prof. Pietro Perona: Measuring algorithmic bias in face analysis — towards an experimental approach</strong></p>
<p><span aria-label="calendar" class="emoji emoji-1f4c5" role="img" title="calendar">:calendar:</span> Tuesday <strong>Feb 23rd, 2021 17:00 – 18:00 CET</strong><br>
<span aria-label="point right" class="emoji emoji-1f449" role="img" title="point right">:point_right:</span> Please use the following zoom link to attend the lecture: <a href="https://authgr.zoom.us/j/98481711168">https://authgr.zoom.us/j/98481711168</a><br>
<span aria-label="light bulb" class="emoji emoji-1f4a1" role="img" title="light bulb">:light_bulb:</span> Learn more about the lecture: <a href="http://www.i-aida.org/future-lectures/">http://www.i-aida.org/future-lectures/</a></p>
<p>The lecture is FREE!</p>
<p>Abstract: Measuring algorithmic bias is crucial both to assess algorithmic fairness, and to guide the improvement of algorithms. Current methods to measure algorithmic bias in computer vision, which are based on observational datasets, are inadequate for this task because they conflate algorithmic bias with dataset bias. To address this problem I will propose experimental method for measuring algorithmic bias of face analysis algorithms, which manipulates directly the attributes of interest, e.g., gender and skin tone, in order to reveal causal links between attribute variation and performance change. The method is based on generating synthetic “transects” of matched sample images that are designed to differ along specific attributes while leaving other attributes constant. A crucial aspect of our approach is relying on the perception of human observers, both to guide manipulations, and to measure algorithmic bias. Besides allowing the measurement of algorithmic bias, synthetic transects have other advantages with respect to observational datasets: sampling  attributes more evenly, allowing for more straightforward bias analysis on minority and intersectional groups, enabling prediction of bias in new scenarios, reducing ethical and legal challenges, and they are economical and fast to obtain, helping make bias testing affordable and widely available. The method is validated by comparing it to a study that employs the traditional observational method for analyzing bias in gender classification algorithms. The two methods reach different conclusions. While the observational method reports gender and skin color biases, the experimental method reveals biases due to gender, hair length, age, and facial hair.</p>



<a name="227749654"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/AIDA%20Lecture%20Series/near/227749654" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anna Tahovská (CLAIRE Office, CZ) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/AIDA.20Lecture.20Series.html#227749654">(Feb 25 2021 at 11:00)</a>:</h4>
<p>On behalf of <a href="https://www.vision4ai.eu/">VISION Project</a>, I would like to invite you to one of the upcoming joint ICT48 activities under the AIDA AI Excellence Lecture Series:<br>
<strong>Lecture by Prof. Björn Schuller: There will be Artificial Emotional Intelligence</strong></p>
<p><span aria-label="calendar" class="emoji emoji-1f4c5" role="img" title="calendar">:calendar:</span> Tuesday <strong>Mar 9th, 2021, 17:00 – 18:00 CET</strong><br>
<span aria-label="point right" class="emoji emoji-1f449" role="img" title="point right">:point_right:</span> Please use the following zoom link to attend the lecture: <a href="https://authgr.zoom.us/j/91839826029">https://authgr.zoom.us/j/91839826029</a><br>
<span aria-label="light bulb" class="emoji emoji-1f4a1" role="img" title="light bulb">:light_bulb:</span> Learn more about the lecture: <a href="http://www.i-aida.org/ai-lectures/">http://www.i-aida.org/ai-lectures/</a></p>
<p>The lecture is FREE!</p>
<p>Abstract: Computers are still largely not connotated with emotional intelligence – even more than two decades after the kick-off of the Affective Computing as the core discipline in this regard. Yet, recently significant advancement took place in the recognition of human emotion and generation of simulated emotional behaviour by computing devices increasingly lending them “Artificial Emotional Intelligence”. This can open up a rich selection of exciting applications to become reality such as completely changing how we interact with computing devices. In this talk, we will dive deep into the latest developments in multimodal Affective Computing from the AI perspective. This includes self-learning of neural architectures by AutoML, reinforcement learning, lifelong and self-supervised learning, “green” efficient learning, federated learning, but also using emotion in learning itself. Furthermore, we will look into robustness issues such as against adversarial attacks or package loss. Beyond showing these and further recent trends and developments largely basing on deep learning techniques, the talk will end on the major needed final steps at “T-minus 3” to make Artificial Emotional Intelligence take-off and “fly” in real-world applications at scale.</p>



<a name="229810724"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/AIDA%20Lecture%20Series/near/229810724" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anna Tahovská (CLAIRE Office, CZ) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/AIDA.20Lecture.20Series.html#229810724">(Mar 11 2021 at 08:16)</a>:</h4>
<p>On behalf of <a href="https://www.vision4ai.eu/">VISION Project</a>, I would like to invite you to one of the upcoming joint ICT48 activities under the AIDA AI Excellence Lecture Series:<br>
<strong>Lecture by Prof. Andreas Geiger: Towards Robust End-to-End Driving</strong></p>
<p><span aria-label="calendar" class="emoji emoji-1f4c5" role="img" title="calendar">:calendar:</span> Tuesday <strong>Mar 23rd, 2021, 17:00 – 18:00 CET</strong><br>
<span aria-label="point right" class="emoji emoji-1f449" role="img" title="point right">:point_right:</span> Please use the following zoom link to attend the lecture: <a href="https://authgr.zoom.us/j/92425987539">https://authgr.zoom.us/j/92425987539</a><br>
<span aria-label="light bulb" class="emoji emoji-1f4a1" role="img" title="light bulb">:light_bulb:</span> Learn more about the lecture: <a href="http://www.i-aida.org/ai-lectures/#event">http://www.i-aida.org/ai-lectures/#event</a></p>
<p>The lecture is FREE!</p>
<p>Abstract: I will present several recent results of my group on learning robust driving policies that have advanced the state-of-the-art in the CARLA self-driving simulation environment. To generalize across diverse conditions, humans leverage multiple types of situation-specific reasoning and learning strategies. Motivated by this observation, I will first present a framework for learning situational driving policies that effectively captures reasoning under varying types of scenarios and leads to 98% success rate on the CARLA self-driving benchmark as well as state-of-the-art performance on a novel generalization benchmark. Next, I will discuss the problem of covariate shift in imitation learning. I will demonstrate that existing data aggregation techniques for addressing this problem have poor generalization performance, and present a novel approach with empirically better generalization performance. Finally, I will talk about the importance of intermediate representations and attention for learning robust self-driving models.</p>



<a name="232231842"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/AIDA%20Lecture%20Series/near/232231842" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anna Tahovská (CLAIRE Office, CZ) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/AIDA.20Lecture.20Series.html#232231842">(Mar 29 2021 at 08:05)</a>:</h4>
<p>On behalf of <a href="https://www.vision4ai.eu/">VISION Project</a>, I would like to invite you to one of the upcoming joint ICT48 activities under the AIDA AI Excellence Lecture Series:</p>
<p><strong>Lecture by Prof. LP Morency: “Multimodal AI: Understanding Human Behaviors”</strong></p>
<p><span aria-label="calendar" class="emoji emoji-1f4c5" role="img" title="calendar">:calendar:</span> Tuesday <strong>Apr 6th, 2021 17:00 – 18:00 CET</strong><br>
<span aria-label="point right" class="emoji emoji-1f449" role="img" title="point right">:point_right:</span> Please use the following zoom link to attend the lecture: <a href="https://authgr.zoom.us/j/94136791572">https://authgr.zoom.us/j/94136791572</a><br>
<span aria-label="light bulb" class="emoji emoji-1f4a1" role="img" title="light bulb">:light_bulb:</span> Learn more about the lecture: <a href="http://www.i-aida.org/ai-lectures/#event">http://www.i-aida.org/ai-lectures/#event</a></p>
<p>The lecture is FREE!</p>
<p>Abstract: Human face-to-face communication is a little like a dance, in that participants continuously adjust their behaviors based on verbal and nonverbal cues from the social context. Today’s computers and interactive devices are still lacking many of these human-like abilities to hold fluid and natural interactions. Leveraging recent advances in machine learning, audio-visual signal processing and computational linguistic, my research focuses on creating computational technologies able to analyze, recognize and predict human subtle communicative behaviors in social context. Central to this research effort is the introduction of new probabilistic models able to learn the temporal and fine-grained latent dependencies across behaviors, modalities and interlocutors. In this talk, I will present some of our recent achievements in multimodal machine learning, addressing five core challenges: representation, alignment, fusion, translation and co-learning.</p>



{% endraw %}

<hr><p>Last updated: Apr 13 2021 at 04:36 UTC</p>