---
layout: archive
title: Zulip Chat Archive
permalink: /stream/201207-events/topic/ECAI.20.20Workshops.html
---

<h2>Stream: <a href="https://claire4ai.github.io/archive/stream/201207-events/index.html">events</a></h2>
<h3>Topic: <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html">ECAI  Workshops</a></h3>

<hr>

<base href="https://claire.zulipchat.com">

<head><link href="https://claire4ai.github.io/archive/style.css" rel="stylesheet"></head>

{% raw %}

<a name="187851003"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/187851003" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ricardo Chavarriaga (CLAIRE Office Switzerland) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#187851003">(Feb 10 2020 at 19:43)</a>:</h4>
<p>======================================================================<br>
=  NeHuAI-2020<br>
=  1st International Workshop on New Foundations for Human-Centered AI<br>
=  June 9, Santiago de Compostela, Spain (Part of ECAI-2020)<br>
=  <a href="http://nehuai2020.aass.oru.se/" target="_blank" title="http://nehuai2020.aass.oru.se/">http://nehuai2020.aass.oru.se/</a><br>
======================================================================</p>
<p>SYNOPSIS</p>
<hr>
<p>In June 2018, the European Commission has appointed a "AI High Level<br>
Expert Group" (AI-HLEG) to support the implementation of the European<br>
Strategy on Artificial Intelligence.  One of the first results of the<br>
AI-HLEG has been to deliver ethics guidelines on Artificial Intelligence<br>
(<a href="https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines" target="_blank" title="https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines">https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines</a>).<br>
These guidelines put forward a human-centered approach to AI, and list<br>
seven key requirements that human-centered, trustworthy AI systems<br>
should meet, summarized by the following headers:</p>
<ol>
<li>Human agency and oversight</li>
<li>Technical robustness and safety</li>
<li>Privacy and data governance</li>
<li>Transparency</li>
<li>Diversity, non-discrimination and fairness</li>
<li>Societal and environmental wellbeing</li>
<li>Accountability</li>
</ol>
<p>Many of today's most popular AI methods, however, fail to meet these<br>
guidelines: making them compliant is a scientific endeavor that is as<br>
crucial as it is challenging and stimulating.  Systems based on deep<br>
learning are a case in point: while these systems often provide<br>
impressive results, their ability to _explain_ these results to the user<br>
is very limited, challenging requirements 4 and 7; in most cases we lack<br>
ways to formally _verify_ their correctness and assess their boundary<br>
conditions, challenging requirement 2; and we don't yet have methods to<br>
allow humans to _collaboratively_ influence or question their decisions,<br>
challenging requirement 1.  Similar criticalities are present in many<br>
other popular AI methods.</p>
<p>This full day workshop will collectively address the fundamental<br>
questions of what are the scientific and technological gaps that we have<br>
to fill in order to make AI systems _human-centered_ in terms of the<br>
above guidelines.</p>
<p>PAPER SUBMISSION</p>
<hr>
<p>Contributions are seeked on new foundations for building Human-Centered<br>
AI systems, able to comply with AI-HLEG recommendations.  Contributions<br>
are seeked in the form of full papers (max 7 pages plus references)<br>
presenting mature results, or position papers and reports of relevant<br>
ongoing work (max 4 pages including references).  More specific topics<br>
include, but are not limited to:</p>
<ul>
<li>Explainable AI</li>
<li>Verifiable AI</li>
<li>Technical robustness and safety of AI systems</li>
<li>Collaboration between humans and AI systems</li>
<li>Integrating model-based and data-driven AI</li>
<li>Integrating symbolic- and sub-symbolic AI</li>
<li>Mixed initiative AI-Human systems</li>
<li>Proactive AI systems in human environments</li>
<li>Understanding and naturally interacting with humans</li>
<li>Understanding and interaction in complex social settings</li>
<li>Reflexivity and expectation managament</li>
<li>Integrating Learning, Reasoning and Acting in AI systems</li>
<li>Integrating human and robot cognition</li>
</ul>
<p>Papers should be formatted according to the ECAI2020 formatting style,<br>
available at the ECAI2020 website (<a href="http://ecai2020.eu" target="_blank" title="http://ecai2020.eu">ecai2020.eu</a>).  Submissions are not<br>
anonymous.</p>
<p>Submit your paper by February 25 via Easychair here:</p>
<p><a href="https://easychair.org/conferences/?conf=nehuai2020" target="_blank" title="https://easychair.org/conferences/?conf=nehuai2020">https://easychair.org/conferences/?conf=nehuai2020</a></p>
<p>ORGANIZERS</p>
<hr>
<ul>
<li>Alessandro Saffiotti (Orebro University, Sweden)</li>
<li>Luciano Serafini (Fondazione Bruno Kessler, Trento, Italy)</li>
<li>Paul Lukowicz (DFKI, Kaiserslautern, Germany)</li>
</ul>
<p>This worskhop is jointly organized by AI4EU (<a href="http://ai4eu.eu" target="_blank" title="http://ai4eu.eu">ai4eu.eu</a>), the EU landmark<br>
project to develop a European AI on-demand platform and ecosystem; and<br>
by Humane-AI (<a href="http://humane-ai.eu" target="_blank" title="http://humane-ai.eu">humane-ai.eu</a>), the EU FET preparatory action devoted to<br>
designing a European research agenda for Human Centered AI.</p>
<p>MORE INFORMATION</p>
<hr>
<p><a href="http://nehuai2020.aass.oru.se/" target="_blank" title="http://nehuai2020.aass.oru.se/">http://nehuai2020.aass.oru.se/</a></p>
<p>======================================================================</p>



<a name="187990379"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/187990379" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ricardo Chavarriaga (CLAIRE Office Switzerland) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#187990379">(Feb 12 2020 at 08:36)</a>:</h4>
<p>CALL FOR PAPERS<br>
TAILOR - Foundations of Trustworthy AI - Integrating Learning, Optimization and Reasoning<br>
1st TAILOR Workshop at ECAI 2020, June 8-9, Santiago de Compostela <a href="https://liu.se/en/research/tailor" target="_blank" title="https://liu.se/en/research/tailor">https://liu.se/en/research/tailor</a></p>
<p>Submission deadline:        March 15, 2020<br>
Notification of acceptance: April  8, 2020<br>
Camera ready paper:         May    8, 2020<br>
Submission link: <a href="https://easychair.org/conferences/?conf=tailor2020" target="_blank" title="https://easychair.org/conferences/?conf=tailor2020">https://easychair.org/conferences/?conf=tailor2020</a></p>
<p>The current scientific landscape is fragmented with many research groups working individually or in smaller constellations in often relatively isolated scientific communities: machine reasoning, machine learning, and optimization are examples of such mostly-disjoint communities.</p>
<p>The TAILOR workshop will bring these groups and researchers together in a unique atmosphere to discuss the state of the art and the latest advances in the integration of learning, optimisation and reasoning to provide the scientific foundations for Trustworthy AI.</p>
<p>The TAILOR community builds upon a large H2020 proposal on building a network of centers of excellence that includes over 100 labs in Europe.<br>
The TAILOR network of research excellence centers focus on the scientific foundations of Trustworthy AI integrating learning, optimisation and reasoning.</p>
<p>The main scientific topics are:</p>
<ul>
<li>
<p>Trustworthiness: How to learn fair AI models, even in spite of biased data? How to develop explainable and interpretable AI decision processes? How to develop transparent AI systems and integrate them into the decision process for increasing user trust?</p>
</li>
<li>
<p>Learning, reasoning and optimisation: How to integrate AI paradigms and representations for reasoning, learning and optimisation in order to support trustworthy AI? Integrated approaches to learning, reasoning and optimisation should allow AI systems to bridge the gap between low-level perception and high-level reasoning, to combine knowledge-based and data-driven methods, to explain their behaviour and allow for introspection of the resulting models.</p>
</li>
<li>
<p>Deciding and Learning How to Act. How to empower an AI system with the ability of deliberating how to act in the world, reasoning on the effects of its actions, learning from past experiences, as well as monitoring the actual or simulated outcome of its actions, learning from possibly unexpected outcomes, and again reasoning and learning how to deal with such new outcome?</p>
</li>
<li>
<p>Reasoning and Learning in Social Contexts. Agents should not reason, learn and act in isolation. They will need to do it with others and among others. So, this topic is  concerned with how AI systems should communicate, collaborate, negotiate and reach agreements with other AI and (eventually) human agents within a multi-agent system (MAS).</p>
</li>
<li>
<p>AutoAI: How to build AI tools, systems, and infrastructure that are performant, robust and trustworthy including having the ability to configure and tune itself for optimal performance? How can we support<br>
(1) people with limited AI expertise and (2)  highly-skilled experts in building such AI systems?</p>
</li>
</ul>
<p>We welcome submissions to the workshop of the following types:</p>
<ol>
<li>
<p>Presentations of relevant work that has recently been published or has already been accepted for publication in journals such as AIJ, JAIR, JMLR, MLJ, and major conferences such as AAAI, ICML, IJCAI, NeurIPS, SIGKDD, etc. The submission should in this case only consist of a copy of the accepted paper.</p>
</li>
<li>
<p>Long papers reporting on new material. Papers can be at most 16 pages in the Springer LNCS format. Please note that also shorter papers are welcome.</p>
</li>
<li>
<p>Extended abstracts that report on novel and preliminary ideas.<br>
Extended abstracts can be at most 6 pages in LNCS format.</p>
</li>
<li>
<p>Short position statements on the topic of the workshop, at most 6 pages in LNCS format.</p>
</li>
</ol>
<p>The workshop is interested in foundational as well as more applied contributions. What matters is that they address the topics of the workshop - the integration of learning, optimisation and reasoning to provide the scientific foundations for Trustworthy AI.</p>
<p>Both long and short papers must be formatted according to ECAI guidelines<br>
(<a href="http://ecai2020.eu/wp-content/uploads/AuthorsPack-ECAI2020.zip" target="_blank" title="http://ecai2020.eu/wp-content/uploads/AuthorsPack-ECAI2020.zip">http://ecai2020.eu/wp-content/uploads/AuthorsPack-ECAI2020.zip</a>) and submitted electronically through EasyChair:<br>
<a href="https://easychair.org/conferences/?conf=tailor2020" target="_blank" title="https://easychair.org/conferences/?conf=tailor2020">https://easychair.org/conferences/?conf=tailor2020</a></p>
<p>Papers accepted for TAILOR 2020 will be published in a Springer LNCS post proceedings.</p>
<p>Organisers<br>
Workshop Chair Fredrik Heintz, <a href="mailto:fredrik.heintz@liu.se" title="mailto:fredrik.heintz@liu.se">fredrik.heintz@liu.se</a>, Linköping<br>
University, Sweden<br>
Luc De Raedt, KU Leuven, Belgium<br>
Peter Flach, University of Bristol, UK<br>
Hector Geffner, ICREA and Universitat Pompeu Fabra, Spain<br>
Fosca Gianotti, National Research Council, Pisa, Italy<br>
Holger Hoos, Leiden University, The Netherlands<br>
Michela Milano, University of Bologna, Italy<br>
Barry O’Sullivan, University College Cork, Ireland<br>
Ana Paiva, University of Lisbon, Portugal<br>
Marc Schoenauer, INRIA, France<br>
Philipp Slusallek, DFKI, Germany<br>
Joaquin Vanschoren, Eindhoven University of Technology, The Netherlands</p>
<div class="message_embed"><a class="message_embed_image" href="https://liu.se/en/research/tailor" style="background-image: url(https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/36100-50065?as=1&amp;w=640&amp;h=420&amp;cr=1&amp;crw=640&amp;crh=420&amp;bc=%23ffffff)" target="_blank"></a><div class="data-container"><div class="message_embed_title"><a href="https://liu.se/en/research/tailor" target="_blank" title="TAILOR Workshop on Trustworthy AI ">TAILOR Workshop on Trustworthy AI </a></div><div class="message_embed_description">The 1st TAILOR (Trustworthy AI - Integrating Learning, Optimization, and Reasoning) Workshop is taking place in Santiago de Compostela on June 8-9, 2020.</div></div></div>



<a name="188062319"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/188062319" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mehul Bhatt <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#188062319">(Feb 12 2020 at 23:07)</a>:</h4>
<p>===  WORKSHOP   /   ECAI 2020.  SPAIN.  ===</p>
<p>Artificial and Human Intelligence<br>
— Formal and Cognitive Foundations for Human-Centred Computing</p>
<p>As part of:  <br>
European Conference on Artificial Intelligence (ECAI 2020)<br>
Santiago de Compostela, Spain - June 8-12 2020</p>
<p>Detailed call  /  <a href="http://www.codesign-lab.org/ecai2020/" target="_blank" title="http://www.codesign-lab.org/ecai2020/">www.codesign-lab.org/ecai2020/</a></p>
<p>/  ABOUT THE WORKSHOP  /  </p>
<p>Artificial and Human Intelligence research addresses the formal &amp; cognitive foundations for human-centred computing, and the human-centred design, development, and usability of cognitive technologies aimed at human-in-the-loop assistance &amp; empowerment in decision-making, planning, creative-technical problem-solving, and automation. The workshop features invited and contributed research advancing the formal and cognitive foundations of human-centred computing particularly from the viewpoints of theories and methods developed within the fields of:</p>
<p>—  Artificial Intelligence<br>
—  Cognitive Science - Psychology<br>
—  Cognitive Neuroscience<br>
—  Visuospatial Cognition and Computation<br>
—  Human-Computer Interaction<br>
—  Design Science - Design Cognition</p>
<p>The principal emphasis of the workshop is on:</p>
<p>(a). the formal and computational foundations of AI and Cognitive Technologies with a principal emphasis on human-centred knowledge representation, semantics, commonsense reasoning, integration of reasoning &amp; learning, and visuospatial representation and reasoning. A particular focus is on integrated commonsense reasoning &amp; learning about space and motion in human-scale embodied multimodal interaction.</p>
<p>(b). behavioural / empirical methods in cognitive science &amp; psychology and neuroscience aimed at investigating human intelligence from the viewpoints of embodiment, multimodal interaction, and visuospatial thinking. A special emphasis of the workshop is on visuospatial cognition and computation, e.g., in the backdrop of aspects pertaining to visual perception, high-level event perception, motion, and narrative-driven perceptual sensemaking.</p>
<p>Particular themes of high interest solicited by the workshop include:</p>
<p>—  knowledge representation - semantics - commonsense - declarative methods<br>
—  semantic interpretation of multimodal human behaviour data<br>
—  integration of reasoning and learning - explainability - neurosymbolism<br>
—  synergy of computational and behavioural / empirical methods<br>
—  data-centred methods for psychology - psychology-driven AI - ``in the wild'' naturalistic experimentation<br>
—  embodiment - visuospatial thinking - motion &amp; interaction - visuospatial perception and cognition<br>
—  design science - design cognition and computation - designing embodied cognitive experiences</p>
<p>The workshop emphasises:  </p>
<p>(i).  <code>In-the-wild'' ecologically valid naturalistic (embodied multimodal interaction) settings;  
(ii).  Bottom-up interdisciplinarity, e.g., combining methods in AI and cognitive psychology; and  
(iii). Design-thinking as a human-centred perspective for engineering (</code>usable'') cognitive technologies aiming to assist, empower, and augment human capability. </p>
<p>We welcome contributions addressing the workshop themes from formal, cognitive, computational, engineering, empirical, psychological, and philosophical perspectives.</p>
<p>/  SUBMISSION REQUIREMENTS  /  </p>
<p>Submitted papers must be formatted according to ECAI 2020 guidelines (refers to workshop website). <br>
Contributions may be submitted as:</p>
<p>—  Technical papers <br>
—  Position / vision statements <br>
—  Work in progress reports or ``new'' project / initiative positioning<br>
—  Poster abstract     (e.g., for early stage PhD candidates) <br>
—  System demonstrations</p>
<p>Details online.</p>
<p>/  IMPORTANT DATES IN 2020  /  </p>
<p>We encourage expression of interest and / or registering an abstract and title (anytime before full submission deadline):</p>
<p>—  Submissions: March 15<br>
—  Notification: April 15<br>
—  Camera Ready: May 10<br>
—  Workshop Date: To be announced<br>
—  ECAI 2020 Conference: June 8 - 12 2020</p>
<p>/  WORKSHOP CHAIR  /  </p>
<p>Mehul Bhatt (Örebro University, Sweden)<br>
Please direct all inquiries to  &gt;  [  <a href="mailto:mehul.bhatt@oru.se" title="mailto:mehul.bhatt@oru.se">mehul.bhatt@oru.se</a>  ]</p>
<p>Workshop details  &gt;  <a href="http://www.codesign-lab.org/ecai2020/" target="_blank" title="http://www.codesign-lab.org/ecai2020/">http://www.codesign-lab.org/ecai2020/</a></p>
<p>================================<br>
Apologies for cross-postings.<br>
================================</p>



<a name="190366315"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/190366315" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexa Kodde (CLAIRE Headquarters, NL) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#190366315">(Mar 12 2020 at 08:39)</a>:</h4>
<p>The deadline for the TAILOR workshop at ECAI is extended to <em>March 29, 2020</em>.</p>



<a name="198091669"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/198091669" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexa Kodde (CLAIRE Headquarters, NL) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#198091669">(May 19 2020 at 16:28)</a>:</h4>
<p>TAILOR Workshop - FINAL CALL FOR PAPERS (extended deadline)</p>
<p>1st TAILOR Workshop at ECAI 2020, Aug 29-30, Santiago de Compostela<br>
<a href="https://liu.se/en/research/tailor">https://liu.se/en/research/tailor</a></p>
<p>Submission deadline:        June  4, 2020 (AOE)<br>
Notification of acceptance: June 23, 2020<br>
Camera ready paper:         July 23, 2020 (AOE)<br>
Submission link: <a href="https://easychair.org/conferences/?conf=tailor2020">https://easychair.org/conferences/?conf=tailor2020</a></p>
<p>In the case that ECAI turns into an online event, we are making plans for taking advantage of the different format. The intention is to do the best of the situation, no matter if it is a physical or an online event.</p>
<p>The current scientific landscape is fragmented with many research groups working individually or in smaller constellations in often relatively isolated scientific communities: machine reasoning, machine learning, and optimization are examples of such mostly-disjoint communities.</p>
<p>The TAILOR workshop will bring these groups and researchers together in a unique atmosphere to discuss the state of the art and the latest advances in the integration of learning, optimisation and reasoning to provide the scientific foundations for Trustworthy AI.</p>
<p>The TAILOR community builds upon a large H2020 proposal on building a network of centers of excellence that includes over 100 labs in Europe. The TAILOR network of research excellence centers focus on the scientific foundations of Trustworthy AI integrating learning, optimisation and reasoning.</p>
<p>The main scientific topics are:</p>
<ul>
<li>
<p>Trustworthiness: How to learn fair AI models, even in spite of biased data? How to develop explainable and interpretable AI decision processes? How to develop transparent AI systems and integrate them into the decision process for increasing user trust?</p>
</li>
<li>
<p>Learning, reasoning and optimisation: How to integrate AI paradigms and representations for reasoning, learning and optimisation in order to support trustworthy AI? Integrated approaches to learning, reasoning and optimisation should allow AI systems to bridge the gap between low-level perception and high-level reasoning, to combine knowledge-based and data-driven methods, to explain their behaviour and allow for<br>
introspection of the resulting models.</p>
</li>
<li>
<p>Deciding and Learning How to Act. How to empower an AI system with the ability of deliberating how to act in the world, reasoning on the effects of its actions, learning from past experiences, as well as monitoring the actual or simulated outcome of its actions, learning from possibly unexpected outcomes, and again reasoning and learning how to deal with such new outcome?</p>
</li>
<li>
<p>Reasoning and Learning in Social Contexts. Agents should not reason, learn and act in isolation. They will need to do it with others and among others. So, this topic is  concerned with how AI systems should communicate, collaborate, negotiate and reach agreements with other AI and (eventually) human agents within a multi-agent system (MAS).</p>
</li>
<li>
<p>AutoAI: How to build AI tools, systems, and infrastructure that are<br>
performant, robust and trustworthy including having the ability to<br>
configure and tune itself for optimal performance? How can we support (1) people with limited AI expertise and (2)  highly-skilled experts in building such AI systems?</p>
</li>
</ul>
<p>We welcome submissions to the workshop of the following types:</p>
<ol>
<li>
<p>Presentations of relevant work that has recently been published or has already been accepted for publication in journals such as AIJ, JAIR, JMLR, MLJ, and major conferences such as AAAI, ICML, IJCAI, NeurIPS, SIGKDD, etc. The submission should in this case only consist of a copy of the accepted paper.</p>
</li>
<li>
<p>Long papers reporting on new material. Papers can be at most 16 pages in the Springer LNCS format. Please note that also shorter papers are welcome.</p>
</li>
<li>
<p>Extended abstracts that report on novel and preliminary ideas.<br>
Extended abstracts can be at most 6 pages in LNCS format.</p>
</li>
<li>
<p>Short position statements on the topic of the workshop, at most 6 pages in LNCS format.</p>
</li>
</ol>
<p>The workshop is interested in foundational as well as more applied<br>
contributions. What matters is that they address the topics of the<br>
workshop - the integration of learning, optimisation and reasoning to provide the scientific foundations for Trustworthy AI.</p>
<p>Both long and short papers must be formatted according to LNCS<br>
guidelines (<a href="https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines">https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines</a>)</p>
<p>and submitted electronically through EasyChair:<br>
<a href="https://easychair.org/conferences/?conf=tailor2020">https://easychair.org/conferences/?conf=tailor2020</a></p>
<p>Papers accepted for TAILOR 2020 will be published in a Springer LNCS post proceedings.</p>
<p>Organisers<br>
Workshop Chair Fredrik Heintz, <a href="mailto:fredrik.heintz@liu.se">fredrik.heintz@liu.se</a>, Linköping<br>
University, Sweden<br>
Luc De Raedt, KU Leuven, Belgium<br>
Peter Flach, University of Bristol, UK<br>
Hector Geffner, ICREA and Universitat Pompeu Fabra, Spain<br>
Fosca Gianotti, National Research Council, Pisa, Italy<br>
Holger Hoos, Leiden University, The Netherlands<br>
Michela Milano, University of Bologna, Italy<br>
Barry O’Sullivan, University College Cork, Ireland<br>
Ana Paiva, University of Lisbon, Portugal<br>
Marc Schoenauer, INRIA, France<br>
Philipp Slusallek, DFKI, Germany<br>
Joaquin Vanschoren, Eindhoven University of Technology, The Netherlands</p>
<p>Program Committee<br>
Maria Garcia De La Banda, Monash University, Australia<br>
Randy Goebel, U Alberta, Canada<br>
Lars Kotthoff, University of Wyoming, USA<br>
Andrea Lodi,  École Polytechnique de Montréal, Canada<br>
Francesca Rossi, IBM, USA<br>
Sylvie Thiebaux, ANU, Australia<br>
Pascal Van Hentenryck, Georgia Institute of Technology, US</p>
<div class="message_embed"><a class="message_embed_image" href="https://liu.se/en/research/tailor" style="background-image: url(https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/36100-50065/tailor-liten?as=1&amp;w=640&amp;h=360&amp;cr=1&amp;crw=640&amp;crh=360&amp;bc=%23ffffff)"></a><div class="data-container"><div class="message_embed_title"><a href="https://liu.se/en/research/tailor" title="TAILOR Workshop on Trustworthy AI ">TAILOR Workshop on Trustworthy AI </a></div><div class="message_embed_description">The 1st TAILOR (Trustworthy AI - Integrating Learning, Optimization, and Reasoning) Workshop is taking place in Santiago de Compostela on &nbsp;29-30 August, 2020.</div></div></div><div class="message_embed"><a class="message_embed_image" href="https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines" style="background-image: url(https://images.springer.com/cda/content/image/cda_displayimage.jpg?SGWID=0-0-16-2208184-0)"></a><div class="data-container"><div class="message_embed_title"><a href="https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines" title="Conference Proceedings guidelines | Springer">Conference Proceedings guidelines | Springer</a></div><div class="message_embed_description">Below you will find Springer's guidelines and technical instructions for the preparation of contributions to be published in one of the following seri</div></div></div>



<a name="198475181"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/ECAI%20%20Workshops/near/198475181" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Pascal <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/ECAI.20.20Workshops.html#198475181">(May 22 2020 at 18:09)</a>:</h4>
<p>Within that context, maybe this is also interesting: <br>
<a href="https://learnai.odsc.com/courses/importance-of-model-fairness-and-interpretability-in-ai-systems">https://learnai.odsc.com/courses/importance-of-model-fairness-and-interpretability-in-ai-systems</a><br>
Speaker is Francesca Lazzeri.</p>
<p>Description<br>
Machine learning model fairness and interpretability are critical for data scientists, researchers and developers to explain their models and understand the value and accuracy of their findings. Interpretability is also important to debug machine learning models and make informed decisions about how to improve them.</p>
<p>In this session, Francesca will go over a few methods and tools that enable you to "unpack” machine learning models, gain insights into how and why they produce specific results, assess your AI systems fairness and mitigate any observed fairness issues.</p>
<p>Using open source fairness and interpretability packages, attendees will learn how to:</p>
<p>Explain model prediction by generating feature importance values for the entire model and/or individual datapoints.<br>
Achieve model interpretability on real-world datasets at scale, during training and inference.<br>
Use an interactive visualization dashboard to discover patterns in data and explanations at training time.<br>
Leverage additional interactive visualizations to assess which groups of users might be negatively impacted by a model and compare multiple models in terms of their fairness and performance.</p>
<p>you could register here -&gt; <a href="https://register.gotowebinar.com/register/2413355861150886926">https://register.gotowebinar.com/register/2413355861150886926</a></p>
<div class="message_embed"><a class="message_embed_image" href="https://learnai.odsc.com/courses/importance-of-model-fairness-and-interpretability-in-ai-systems" style="background-image: url(https://thinkific-import.s3.amazonaws.com/59871/ZIooYFXRQUmGZW80ExhW_learn_ai_speaker_cards.png)"></a><div class="data-container"><div class="message_embed_title"><a href="https://learnai.odsc.com/courses/importance-of-model-fairness-and-interpretability-in-ai-systems" title="UPCOMING WEBINAR: The Importance of Model Fairness and Interpretability in AI Systems">UPCOMING WEBINAR: The Importance of Model Fairness and Interpretability in AI Systems</a></div><div class="message_embed_description">Date: May 25, 2020
Time: 1 pm – 2:30 pm EDT</div></div></div>



{% endraw %}

<hr><p>Last updated: May 25 2021 at 15:01 UTC</p>