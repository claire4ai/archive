<html>
<head><meta charset="utf-8"><title>nature opinion piece on AI · CLAIRE news · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://claire4ai.github.io/archive/stream/201957-CLAIRE-news/index.html">CLAIRE news</a></h2>
<h3>Topic: <a href="https://claire4ai.github.io/archive/stream/201957-CLAIRE-news/topic/nature.20opinion.20piece.20on.20AI.html">nature opinion piece on AI</a></h3>

<hr>

<base href="https://claire.zulipchat.com">

<head><link href="https://claire4ai.github.io/archive/style.css" rel="stylesheet"></head>

<a name="203113055"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201957-CLAIRE%20news/topic/nature%20opinion%20piece%20on%20AI/near/203113055" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Leopold <a href="https://claire4ai.github.io/archive/stream/201957-CLAIRE-news/topic/nature.20opinion.20piece.20on.20AI.html#203113055">(Jul 07 2020 at 14:56)</a>:</h4>
<p>would be interested in hearing comments on this opinion published on <a href="http://nature.com">nature.com</a>: <a href="https://www.nature.com/articles/d41586-020-02003-2">https://www.nature.com/articles/d41586-020-02003-2</a></p>
<div class="message_embed"><a class="message_embed_image" href="http://nature.com" style="background-image: url(http://media.springernature.com/lw630/nature-cms/uploads/cms/pages/2913/top_item_image/mars1-4f57469cd0a7ae176aad866baf0d3147.jpg)"></a><div class="data-container"><div class="message_embed_title"><a href="http://nature.com" title="Nature">Nature</a></div><div class="message_embed_description">Nature is the world’s foremost international weekly scientific journal and is the flagship journal for Nature Research. It publishes the finest peer-reviewed ...</div></div></div><div class="message_embed"><a class="message_embed_image" href="https://www.nature.com/articles/d41586-020-02003-2" style="background-image: url(https://media.nature.com/lw1024/magazine-assets/d41586-020-02003-2/d41586-020-02003-2_18150240.jpg)"></a><div class="data-container"><div class="message_embed_title"><a href="https://www.nature.com/articles/d41586-020-02003-2" title="Don’t ask if artificial intelligence is good or fair, ask how it shifts power">Don’t ask if artificial intelligence is good or fair, ask how it shifts power</a></div><div class="message_embed_description">Those who could be exploited by AI should be shaping its projects.</div></div></div>



<a name="204292444"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201957-CLAIRE%20news/topic/nature%20opinion%20piece%20on%20AI/near/204292444" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wlodzislaw Duch <a href="https://claire4ai.github.io/archive/stream/201957-CLAIRE-news/topic/nature.20opinion.20piece.20on.20AI.html#204292444">(Jul 18 2020 at 09:04)</a>:</h4>
<p><span class="user-mention silent" data-user-id="232664">Leopold</span> <a href="#narrow/stream/201957-CLAIRE-news/topic/nature.20opinion.20piece.20on.20AI/near/203113055">said</a>:</p>
<blockquote>
<p>would be interested in hearing comments on this opinion published on <a href="http://nature.com">nature.com</a>: <a href="https://www.nature.com/articles/d41586-020-02003-2">https://www.nature.com/articles/d41586-020-02003-2</a></p>
</blockquote>
<p>Some good points in here, but  as many articles nowadays AI is narrowed to a few technologies that are used to track people or to create their profiles for political or commercial purposes. We as a community should stress that scientific development and decisions to use particular programs for specific tasks are two different things. What percentage of all AI research is linked to such applications? If an organization, such as government body, is using programs that have not been tested properly, should AI be blamed (or maybe computer science, or maybe mathematics), or should it be the responsibility of  the organization? To whom should complaints be addressed? Are people less biased and make less errors than programs? Corrections to software may remove the problem, but can people's minds be corrected? <br>
UNESCO is organizing discussions about AI ethics and wants to issue guidance - but for whom? People working on AI algorithms, or users of decision support systems that have not been properly tested? Perhaps we need better AI systems, carefully comparing the effects of their introduction with results of our current procedures. Reducing AI to a few specific applications is bad for the field. Telemarketing has been justly criticized, but no-one blamed engineering, or phone producers who created enabling technology.</p>



<a name="204339411"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201957-CLAIRE%20news/topic/nature%20opinion%20piece%20on%20AI/near/204339411" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Gregg Barrett (Cirrus, South Africa) <a href="https://claire4ai.github.io/archive/stream/201957-CLAIRE-news/topic/nature.20opinion.20piece.20on.20AI.html#204339411">(Jul 19 2020 at 08:38)</a>:</h4>
<p>Unfortunately, UNESCO (like many others concerning themselves with such matters) knows close to nothing about AI / machine learning. Discussions about validation data, test data and loss functions are in most instances not even on the agenda. I have doubts that even matters pertaining to law can substantively be discussed due to a total lack of understanding.<br>
The way forward is for practitioners to provide their own code of conduct - for example, as was done with the Financial Modelers' Manifesto: <a href="https://www.uio.no/studier/emner/sv/oekonomi/ECON4135/h09/undervisningsmateriale/FinancialModelersManifesto.pdf">https://www.uio.no/studier/emner/sv/oekonomi/ECON4135/h09/undervisningsmateriale/FinancialModelersManifesto.pdf</a></p>



<hr><p>Last updated: Mar 02 2022 at 12:24 UTC</p>
</html>