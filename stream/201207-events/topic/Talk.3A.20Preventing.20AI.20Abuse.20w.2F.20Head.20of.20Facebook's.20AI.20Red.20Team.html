<html>
<head><meta charset="utf-8"><title>Talk: Preventing AI Abuse w/ Head of Facebook&#x27;s AI Red Team · events · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://claire4ai.github.io/archive/stream/201207-events/index.html">events</a></h2>
<h3>Topic: <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/Talk.3A.20Preventing.20AI.20Abuse.20w.2F.20Head.20of.20Facebook&#x27;s.20AI.20Red.20Team.html">Talk: Preventing AI Abuse w/ Head of Facebook&#x27;s AI Red Team</a></h3>

<hr>

<base href="https://claire.zulipchat.com">

<head><link href="https://claire4ai.github.io/archive/style.css" rel="stylesheet"></head>

<a name="204643951"></a>
<h4><a href="https://claire.zulipchat.com#narrow/stream/201207-events/topic/Talk%3A%20Preventing%20AI%20Abuse%20w/%20Head%20of%20Facebook%27s%20AI%20Red%20Team/near/204643951" class="zl"><img src="https://claire4ai.github.io/archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexa Kodde (CLAIRE Headquarters, NL) <a href="https://claire4ai.github.io/archive/stream/201207-events/topic/Talk.3A.20Preventing.20AI.20Abuse.20w.2F.20Head.20of.20Facebook&#x27;s.20AI.20Red.20Team.html#204643951">(Jul 22 2020 at 09:03)</a>:</h4>
<p>The ACM Learning Center presents:</p>
<p><strong>July 24 Talk on Preventing AI Abuse with Head of Facebook's AI Red Team Cristian Canton</strong></p>
<p>If you haven't done so already, register now (<a href="https://webinars.on24.com/acm/Canton?partnerref=rembull">https://webinars.on24.com/acm/Canton?partnerref=rembull</a>) for the next free ACM TechTalk, "<strong>Abuses and Misuses of AI: Prevention vs. Reaction</strong>" presented on <strong>Friday, July 24 at 1:00 PM ET/10:00 AM PT</strong> by <strong>Cristian Canton</strong>, Research Manager on the AI Integrity Team at Facebook AI. <strong>Juan Miguel De Joya</strong>, Project Officer for AI for Good, United Nations International Telecommunications Union Member, and ACM Practitioner Board Member, will moderate the questions and answers session following the talk.</p>
<p>Leave your comments and questions with our speaker now and any time before the live event onACM's Discourse Page (<a href="https://on.acm.org/t/abuses-and-misuses-of-ai-prevention-vs-reaction/1736">https://on.acm.org/t/abuses-and-misuses-of-ai-prevention-vs-reaction/1736</a>). And check out the page after the webcast for extended discussion with your peers in the computing community, as well as further resources on AI abuse prevention and strategies.</p>
<p>(If you'd like to attend but can't make it to the virtual event, you still need to register to receive a recording of the TechTalk when it becomes available.)</p>
<p>Note: You can stream this and all ACM TechTalks on your mobile device, including smartphones and tablets.</p>
<p>As AI is becoming more ubiquitous and part of almost every aspect of our lives, professional and personal, it is necessary to consider potential harmful aspects of it: from exploitation of AI weaknesses for nefarious purposes (e.g. adversarial attacks against classifier) to abuses of harmless technologies (e.g. deepfakes to spread misinformation). Reactively addressing these AI mis/ab-uses when they have been already executed has proven to be costly in many dimensions (human, economic, etc.); hence a more preventive approach emerges as an alternative. In this talk we will do a walkthrough of some of these adversarial AI scenarios and how a red team mentality may be a viable strategy, with some examples.</p>
<p>Duration: 60 minutes (including audience Q&amp;A) </p>
<p>**Presenter:<br>
Cristian Canton**, Facebook AI Red Team<br>
Cristian Canton is a Research Manager on the AI Integrity Team at Facebook AI. He currently supports the AI Red Team, which focuses on understanding weaknesses and vulnerabilities derived from the use (or misuse) of AI, related to misinformation and election interference. From 2012-16, he was at Microsoft Research in Redmond (USA) and Cambridge (UK); from 2009-2012, he was at Vicon (Oxford), bringing computer vision to produce visual effects for the cinema industry. He got his PhD and MS from Technical University of Catalonia (Barcelona) and his MS Thesis from EPFL (Switzerland) on computer vision topics.</p>
<p>**Moderator:<br>
Juan Miguel De Joya**, Project Officer for AI for Good, United Nations International Telecommunications Union Member, ACM Practitioner Board<br>
Juan Miguel de Joya is a Project Officer for AI for Good at the International Telecommunications Union, the United Nations agency specializing in information and communication technologies. Prior to this role, he served as a contractor at Facebook/Oculus, Google, DigitalFish, Pixar Animation Studios, and Walt Disney Animation Studios, and was an undergraduate researcher in graphics at the Visual Computing Lab at the University of California, Berkeley. In his spare time, he is part of the ACM Practitioner Board, the ACM Professional Development Committee, the ACM Future of Computing Academy, and the ACM SIGGRAPH Strategy Group. His current interests include artificial intelligence, computer graphics, computational physics, the internet, digital identity, and the human impact of computing in society at large.</p>
<p>Visit <a href="https://learning.acm.org/techtalks-archive">https://learning.acm.org/techtalks-archive</a> for our full archive of past TechTalks.</p>
<div class="message_embed"><a class="message_embed_image" href="https://webinars.on24.com/acm/Canton?partnerref=rembull" style="background-image: url(https://event.on24.com/event/23/70/53/6/rt/1/images/socialsharing/2019cristian_canton_squarecrop.jpg)"></a><div class="data-container"><div class="message_embed_title"><a href="https://webinars.on24.com/acm/Canton?partnerref=rembull" title="Abuses and Misuses of AI: Prevention vs. Reaction">Abuses and Misuses of AI: Prevention vs. Reaction</a></div><div class="message_embed_description">Friday, July 24, 2020 at 01:00 PM Eastern Daylight Time. In this talk we will do a walkthrough of some adversarial AI scenarios and how a red team mentality may be a viable strategy, with some examples.</div></div></div><div class="message_embed"><a class="message_embed_image" href="https://on.acm.org/t/abuses-and-misuses-of-ai-prevention-vs-reaction/1736" style="background-image: url(https://aws1.discourse-cdn.com/acm/original/1X/6bced230017c62333a39abaabad63249093408a9.png)"></a><div class="data-container"><div class="message_embed_title"><a href="https://on.acm.org/t/abuses-and-misuses-of-ai-prevention-vs-reaction/1736" title="Abuses and Misuses of AI: Prevention vs. Reaction">Abuses and Misuses of AI: Prevention vs. Reaction</a></div><div class="message_embed_description">Title: Abuses and Misuses of AI: Prevention vs. Reaction  Date: Friday, July 24, 1:00 PM ET/10:00 AM PT  Duration: 1 hr  Speaker:  Cristian Canton, Facebook AI Red Team  Resources:  Tech Talk Registration  The AI Ladder (O’Reilly Book, Free for ACM Members)  The AI Organization (O’Reilly Book, Free for ACM Members)  Artificial Intelligence Safety and Security (Skillsoft Book, Free for ACM Members)  Keeping Your AI Under Control: A Pragmatic Guide to Identifying, Evaluating, and Quantifying Risks ...</div></div></div>



<hr><p>Last updated: Jun 18 2022 at 11:51 UTC</p>
</html>